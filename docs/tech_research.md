A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
オープンソースジョブ管理システム：エフェメラル・シングルタスクランナーアーキテクチャのための技術評価レポートI. エグゼクティブサマリー問題提起本レポートは、特定のユースケースに合致するオープンソースの「MCPサーバー」またはジョブマネージャーの選定を目的としています。要求されるシステムは、ジョブの状態を監視し、保留中のタスクが存在しかつアクティブなランナーがいない場合に限り、短命（short-lived）かつシングルタスクのランナーを起動するという、明確なアーキテクチャパターンを実装する必要があります。さらに、このランナーは、自身のタスク実行中に新たなサブタスクを動的にキューに追加できる能力を持つことが求められます。分析アプローチこの要求に応えるため、本レポートでは2つの主要なアーキテクチャパラダイム、「分散タスクキュー」と「最新のワークフローオーケストレーションエンジン」を比較分析します。各候補ソリューションは、ユーザーが指定したワーカーのライフサイクル管理、コントロールプレーンのロジック、動的なワークフロー生成能力という3つの主要な評価基準に基づいて厳密に評価されます。主要な調査結果分析の結果、Celeryのような従来のタスクキューは、その柔軟性から要求されたパターンに適応可能であるものの、中核となる「MCP」ロジック（ジョブ状態の監視とワーカーの起動制御）を実装するためには、ユーザー側で大規模なカスタム開発が必要となることが明らかになりました。これに対し、Apache Airflow（特にKubernetesExecutorを使用した場合）やPrefectといった最新のワークフローオーケストレーターは、要求されているエフェメラル（短命）なワーカーモデルをよりネイティブにサポートするアーキテクチャを提供しています。主な推奨事項本レポートの主要な推奨事項は、Apache AirflowとKubernetesExecutorの組み合わせです。この構成は、ユーザーが要求するアーキテクチャを最も直接的かつネイティブに実装するものです。Airflowのスケジューラーが「MCPサーバー」として機能し、KubernetesExecutorがタスクごとに短命なワーカー（Pod）を起動・終了させる役割を担います。これにより、カスタムの制御ロジックを開発する必要なく、要求された動作モデルを実現できます。ただし、このソリューションはKubernetesクラスターの運用を前提とします。Kubernetes環境がない、またはPythonネイティブな開発体験を優先する場合には、Prefectが強力な代替案となります。II. はじめに：現代アーキテクチャにおける「MCPサーバー」の再定義ユーザーからの「MCPサーバー」という要求は、分散システムにおけるジョブ管理のための集中管理プレーン、すなわち「コントロールプレーン」または「オーケストレーター」を求めるものと解釈できます。このセクションでは、この要求を現代のクラウドネイティブアーキテクチャの文脈で再定義し、評価の基盤を確立します。中核的要求の解釈ユーザーが提示した「ジョブステータスをポーリングする」というメカニズムは、コントロールループの一実装形態です。これは、定期的に状態を確認し、必要なアクションを実行するという古典的なモデルを示唆しています。しかし、現代のシステムでは、キューの深さのメトリクスに反応する（1）あるいはウェブフックを利用する（2）など、より効率的なイベント駆動型のアプローチが存在します。ユーザーが記述しているのは、達成したい「振る舞い」であり、その実装メカニズムとしての「カスタムポーリングループ」は、最新のオーケストレーションシステムにおいてはアンチパターンとなり得ます。これは、CeleryのワーカーやAirflowのスケジューラーのような専用コンポーネントが、この問題をより堅牢かつ効率的に解決しているためです（3）。したがって、本レポートの目的は、この管理ロジックを自作するためのライブラリを探すことではなく、この管理機能を内包した完全なシステムを見つけることにあります。エフェメラル・シングルタスクワーカーパターンユーザーの要求で最も特徴的なのは、「短命（short-lived）かつシングルタスクのランナー」というワーカーモデルです。これは、ワーカーが必要に応じて起動され、単一のタスクを実行した後に即座に終了するというパターンです。このモデルは、AWS Lambdaのようなサーバーレス関数や、Kubernetes Jobsのようなコンテナベースのジョブ実行と密接に関連しています。このパターンは、リソースのオンデマンド利用とタスク間の厳密な分離を優先するものであり、多くのシステムで標準的な、低レイテンシを目的とした永続的なワーカーモデルとは対照的です。この要求は、ユーザーのインフラストラクチャ戦略がコンテナネイティブまたはサーバーレスに基づいていることを強く示唆しています。そのため、Kubernetesやコンテナとの親和性が高いソリューション（例：AirflowのKubernetesExecutor 6、PrefectのDocker/Kubernetesワーカー 8）は、手動での適応が必要なソリューションと比較して、運用上の優位性を持ちます。動的ワークフローの課題「新たなサブタスクをキューに追加する」という要件は、実行時にワークフローの構造が変化する、データ駆動型の動的なグラフ生成能力を求めるものです。この機能は、処理対象のデータによって後続のタスク数が変動するような、予測不可能な複雑なワークフローにおいて不可欠であり、高度なオーケストレーションシステムを評価する上での重要な差別化要因となります（10）。評価基準の定義以上の分析に基づき、候補となるソリューションは以下の4つの主要な基準に沿って評価されます。コントロールプレーンアーキテクチャ: ジョブの状態監視とワーカーの起動トリガーはどのように実装されているか。ワーカーライフサイクル管理: システムは短命なシングルタスクワーカーをネイティブにサポートしているか、あるいは適応可能か。動的ワークフロー能力: 実行時における新たなタスクの生成をどのようにサポートしているか。運用オーバーヘッドとエコシステム: インフラストラクチャへの依存関係、デプロイメント、およびメンテナンスの複雑性はどの程度か。III. アーキテクチャパラダイム：タスクキュー vs. ワークフローオーケストレーターユーザーの要求を満たす可能性のあるシステムは、主に「分散タスクキュー」と「ワークフローオーケストレーションエンジン」という2つのカテゴリに分類されます。両者は似た目的を持つことがありますが、そのアーキテクチャと設計思想には根本的な違いがあります。パラダイム1：分散タスクキュー（Celery, RQ, Dramatiq）コアアーキテクチャ: このモデルは、プロデューサー（タスク発行者）、ブローカー（メッセージキュー）、コンシューマー（ワーカー）というシンプルかつ強力な構成要素から成り立ちます（3）。その主眼は、個別の関数呼び出し（タスク）を複数のマシンやプロセスに分散させることにあります。状態管理: タスクの状態は通常、ブローカーとは別の結果バックエンド（例：Redisやデータベース）で管理されます（3）。「ジョブ」という概念は、多くの場合タスクの集合体として表現され、タスク間の依存関係といったワークフローロジックは、CeleryのCanvasのような特定のAPI呼び出しを通じてプロデューサー側で定義されます（17）。ワーカーモデル: デフォルトのワーカーモデルは、ブローカーを継続的にポーリングし、新しいタスクを取得して実行する、長寿命の永続的なプロセスです（1）。これは、ユーザーが要求する短命なワーカーモデルとは正反対の設計です。適合性: これらのツールは非同期タスク実行には非常に強力ですが、ユーザーが求める高レベルな「ジョブ管理」コントロールプレーンを本質的に提供するものではありません。パラダイム2：ワークフローオーケストレーションエンジン（Airflow, Prefect, Dagster）コアアーキテクチャ: こちらは、スケジューラー、メタデータデータベース、エグゼキューター、ワーカー/ランナーといった、より複雑でステートフルなアーキテクチャを採用しています（4）。その主眼は、複数のステップからなるワークフロー（「DAG」や「Flow」と呼ばれる）全体のライフサイクルを管理することにあります。状態管理: メタデータデータベースが、すべてのワークフロー実行とタスクインスタンスの状態に関する信頼できる唯一の情報源（Single Source of Truth）として機能します（4）。これにより、豊富な実行履歴の追跡と高度な可観測性が実現されます。ワーカーモデル: これらのシステムはワーカーモデルにおいて高い柔軟性を持ちます。永続的なワーカー（例：AirflowのCeleryExecutor）を利用することも可能ですが、タスクごとにエフェメラルな実行環境を生成するために特別に設計されたエグゼキューターも提供されています（例：AirflowのKubernetesExecutor 6、PrefectのWork Pool 2）。適合性: これらのプラットフォームは、ユーザーが探している「MCPサーバー」（スケジューラー/オーケストレーションエンジン）をその中核に内包しています。したがって、評価の焦点は、そのワーカーモデルと動的ワークフロー能力が、ユーザーの特定の要件とどれだけ適合するかに移ります。両パラダイムの根本的な違いは、「インテリジェンス」の所在にあります。タスクキューシステムでは、インテリジェンスはプロデューサー（ワークフローを定義する）とワーカー（コードを実行する）に分散しており、ブローカーは単純なメッセージバスとして機能します。一方、オーケストレーションエンジンでは、インテリジェンスはスケジューラーとメタデータデータベースに集約されています。スケジューラーはワークフロー全体のグラフ、依存関係、履歴を理解しています。この中央集権的なアプローチこそが、「特定のジョブに対してアクティブなランナーが他にない場合にのみランナーを起動する」といった、ユーザーが求める高度な制御を可能にするのです。単純なタスクキューには、「ジョブのアクティブなランナー」というネイティブな概念はなく、タスクキューの上にステートフルな管理レイヤーを自作することでしか実現できません。IV. 分散タスクキューの詳細分析このセクションでは、タスクキューをユーザーの要求モデルに適応させる可能性を探ります。これは、ユーザー自身がカスタムのコントロールプレーンを構築することを前提とした評価です。A. Celery：業界標準の強力なタスクキューアーキテクチャ: Celeryは、クライアント、ブローカー（RabbitMQ, Redisなど）、ワーカー、結果バックエンドという4つの主要コンポーネントで構成されます（3）。その成熟度、豊富な機能、そしてPythonエコシステムでの広範な採用実績は特筆に値します（23）。コントロールプレーンの実装:ジョブ状態のポーリング: ユーザーは、CeleryのAPI（AsyncResultオブジェクトの追跡など）や結果バックエンドを直接クエリするカスタムの管理スクリプトを作成する必要があります。これは、状態管理とロジックを完全に自作することを意味します。ワーカーの起動: 管理スクリプトは、特定のジョブに対応するキューのために、Celeryワーカーを実行するコンテナやプロセスを起動し、タスク完了後にそれを終了させる責務を負います。このパターンの実現可能性は、AWS BatchとCeleryを組み合わせた事例で示されています。この事例では、Bashスクリプトがワーカーを起動し、SQSキューの状態をループで確認し、キューが空になったらワーカープロセスにTERMシグナルを送信して終了させています（1）。これは可能であるものの、完全にオーダーメイドの実装となります。ワーカーロジックの実装:短命・シングルタスクランナー: Celeryワーカーは、--concurrency=1とmax-tasks-per-child=1というフラグを組み合わせることで、1つのタスクを処理した後に終了するように設定できます。これを前述のライフサイクル管理スクリプトと組み合わせることで、要求されたワーカーの振る舞いを実現できます。動的なサブタスク生成: これはCeleryの大きな強みです。ワーカーは実行中にCanvas API（chain、group、chordなど）を使用して、新たなタスクをキューに追加し、複雑なサブワークフローを動的に定義できます（17）。また、動的なキュー生成とルーティング機能を使えば、サブタスクを特定のキューに分離することも可能です（25）。評価: Celeryは非常に柔軟で強力ですが、ユーザーが要求する「MCP」コントロールループのロジック全体を自ら設計・実装・維持する必要があります。Celeryが提供するのはライブラリであり、この特定のアーキテクチャパターンに対するすぐに使えるソリューションではありません。B. Redis Queue (RQ)：シンプルさを追求した代替案アーキテクチャ: RQは、ブローカーと結果バックエンドの両方にRedisのみを使用するという、よりシンプルな設計を特徴としています（23）。コントロールプレーンの実装:ジョブ状態のポーリング: 管理スクリプトは、Job.fetch('job_id', connection=redis)を使用して特定のジョブの状態を取得できます（27）。さらに、RQのジョブ登録（Job Registries）機能（StartedJobRegistry、FinishedJobRegistryなど）を使えば、特定の状態にあるジョブのリストを効率的に問い合わせることが可能です（27）。ワーカーの起動: RQの決定的な特徴はバーストモード（rq worker --burst）です（19）。このコマンドラインフラグは、ワーカーに指定されたキュー内の全てのジョブを実行し、キューが空になったら自動的に終了するよう指示します。これは、ユーザーが求める短命なワーカーの概念をネイティブにサポートしています。これにより、管理スクリプトの責務は、「保留中のジョブがあり、アクティブなワーカーがいないことを確認し、rq worker --burst my_job_queueを実行する」という、よりシンプルなものになります。ワーカーロジックの実装:短命・シングルタスクランナー: バーストモードのワーカーは、厳密には「シングルタスク」ではなく、キューを空にするまでタスクを処理します。真のシングルタスクランナーを実現するためには、管理スクリプトがワーカーを起動する前に、ジョブ固有のキューにタスクが1つだけ存在することを保証する必要があります。動的なサブタスク生成: RQワーカーはPython関数を実行するだけなので、その関数内でキューに接続し、q.enqueue()を呼び出すことで新しいジョブを簡単に追加できます（31）。depends_on引数による依存関係の定義もサポートされています（33）。評価: RQのバーストモードは、Celeryと比較して短命ワーカーの実装を大幅に簡素化する魅力的な機能です。しかし、依然としてジョブの状態をポーリングし、ワーカーをいつ起動するかを決定するカスタムの管理ロジックはユーザーが構築する必要があります。これらのタスクキューをユーザーの要求に適用しようとすると、アーキテクチャの逆転が生じます。CeleryやRQの標準的な設計は、ワーカーが安価で永続的なリソースであり、タスクがエフェメラルな作業単位であることを前提としています。しかし、ユーザーの要求はこの関係を逆転させ、「ジョブ」が永続的な論理エンティティとなり、「ワーカー」がオンデマンドで確保されるエフェメラルな計算リソースとなります。このパターンを強制することは可能ですが、フレームワークの自然な設計思想に逆らうものであり、ネイティブにこのパターンをサポートするシステムと比較して、脆弱性やメンテナンスオーバーヘッドの増大につながる可能性があります。V. ワークフローオーケストレーションエンジンの詳細分析このセクションでは、「MCPサーバー」が中核的な組み込みコンポーネントとして提供されるプラットフォームを評価します。A. Apache Airflow：KubernetesExecutorによるエフェメラルワーカーアーキテクチャ: Airflowは、スケジューラー、ウェブサーバー、メタデータデータベース、そしてエグゼキューターというコアコンポーネントで構成されます（4）。エグゼキューターはプラグイン可能なコンポーネントであり、タスクの実行方法を定義します。コントロールプレーンとワーカーライフサイクル:KubernetesExecutor: これがこの文脈におけるAirflowの最も重要な機能です。KubernetesExecutorは、Airflowの各タスクインスタンスを、Kubernetes APIへの新しい専用Podの起動要求として扱います（6）。Podが作成され、単一のタスクを実行し、完了後に終了します。この動作は、ユーザーが要求する「短命・シングルタスクランナー」の要件を完璧かつネイティブに実装しています。ポーリングと起動: ユーザーはポーリングループを自作する必要がありません。Airflowスケジューラーがメタデータデータベース内のDAG実行（DagRun）とタスクの状態を監視します（36）。タスクの依存関係が満たされると、スケジューラーはKubernetesExecutorにPodの起動を指示します。「アクティブなランナーがいない」という条件は、Airflowのステートマシンによって暗黙的に管理されます。動的なサブタスク生成:動的タスクマッピング: Airflow 2.3以降で導入されたexpand()関数により、あるタスクが実行時にリストや辞書を返すことで、後続のタスクがその出力の各要素に対して「マッピング」され、並列なタスクインスタンス群が動的に生成されます（10）。これは、前のタスクの出力に基づいてサブタスクを作成するという要求に直接応える機能です。評価: KubernetesExecutorを使用したAirflowは、極めて有力な候補です。要求されたコントロールプレーンとワーカーライフサイクルモデルを、追加開発なしで提供します。主な検討事項は、運用環境としてKubernetesクラスターが必須となる点です。B. Prefect：動的ハイブリッドオーケストレーターアーキテクチャ: Prefectは、Prefect API（サーバーまたはクラウド）とワーカーという疎結合なモデルを採用しています（8）。APIがオーケストレーションを行い、ユーザー環境で実行されるワーカーが実際の処理を担当します。ワーカーは「ワークプール」をポーリングし、スケジュールされた実行（Flow Run）を見つけると、その実行に必要なインフラ（例：サブプロセス、Dockerコンテナ、Kubernetesジョブ）をプロビジョニングします（2）。コントロールプレーンとワーカーライフサイクル:ワーカー/ワークプールモデル: ProcessWorkerやDockerWorkerは、各フロー実行（Flow Run）ごとに新しい分離されたOSプロセスやコンテナを起動します。このプロセスはフローを実行し、完了後に終了します。これは「短命」という要件とよく一致しますが、その単位はタスクごとではなく、フロー実行ごとである点に注意が必要です。run_onceモード: Prefectワーカーは--run-onceフラグ付きで起動できます（8）。これにより、ワーカーは一度だけワークプールをポーリングし、見つかったジョブを実行した後にシャットダウンします。これはRQのバーストモードに類似しており、エフェメラルな実行を実現するもう一つのメカニズムです。ポーリングと起動: Prefect APIサーバーがコントロールプレーンです。ユーザーの管理スクリプトは、APIをクエリしてフロー実行の状態を確認し（40）、run_onceワーカーを起動するかどうかを決定できます。しかし、よりPrefectらしいパターンは、ワークプールをポーリングする長寿命のワーカーを起動しておくことです。この場合、システムが実行のピックアップを保証しますが、ワーカー自体は永続的です。ユーザー特有の「ジョブごとに1つのランナー」モデルを厳密に実現するには、ワークキューの同時実行数制限（42）などを利用したカスタムロジックが必要になります。動的なサブタスク生成:ネイティブなPythonicワークフロー: これはPrefectの核となる強みです。フローが純粋なPythonコードであるため、動的な振る舞いは自然に実装できます。タスクは、自身の実行結果に基づいて、ループや条件分岐の中で他のタスクやフローを呼び出すことができます。Prefectのエンジンは、特別な構文なしでこれらの「動的DAG」をネイティブに処理するように設計されています（43）。評価: Prefectは動的ワークフローに対して卓越したサポートを提供します。その実行モデルはフロー実行レベルでエフェメラルです。「シングルタスクランナー」と「1つのアクティブなランナー」というユーザーの制約に完璧に一致させるためには、ワークフローのモデリング（例：シングルタスクのサブフローを多用する）やカスタムロジックが必要ですが、タスクキューと比較して、自作する部分は格段に少なくなります。ここで重要なのは、エフェメラルな実行単位がAirflowとPrefectで決定的に異なる点です。AirflowのKubernetesExecutorはタスクインスタンスをエフェメラルな実行単位とします（6）。DAGの各ノードがそれぞれ独自のPodで実行されます。一方、Prefectのワーカーモデルはフロー実行をエフェメラルな実行単位とします（8）。ワークフロー全体が単一のコンテナやプロセスで実行されます。ユーザーの「シングルタスクランナー」というモデルに対しては、Airflowがより直接的な1対1のマッピングを提供します。Prefectで同じことを実現するには、メインのジョブを、多数の小さなシングルタスクの「サブフロー」を起動する「オーケストレーターフロー」として設計する必要があるでしょう。VI. 比較分析と機能マッピングこれまでの詳細な分析を統合し、意思決定を支援するための明確なフレームワークを提示します。以下の比較表は、各候補ソリューションをユーザーの要件に照らして評価したものです。表1：MCPサーバー実装のための機能比較マトリクス要件Celery (カスタムマネージャー併用)RQ (カスタムマネージャー併用)Airflow (KubernetesExecutor)Prefect (Work Pools)コントロールプレーン (MCP)ユーザー構築: ポーリングと状態管理のためのカスタムスクリプトが必須。ユーザー構築: よりシンプルなAPI (Job.fetch, レジストリ) を持つが、依然としてカスタムスクリプトが必要。組み込み: Airflowスケジューラーは堅牢な本番環境グレードのコントロールプレーンとして機能する。組み込み: Prefect APIサーバーは堅牢な本番環境グレードのコントロールプレーンとして機能する。ワーカー起動ロジック手動: カスタムスクリプトが保留タスクとアクティブワーカーの有無を確認する必要がある。手動: カスタムスクリプトが状態を確認し、rq worker --burstを起動する必要がある。自動: スケジューラーが依存関係と状態に基づき、タスクのキューイングとPodの作成を自動で処理する。自動 (標準) / 手動 (run_once): 標準ワーカーは自動ポーリング。ユーザーモデルにはrun_onceワーカーの起動が必要。ワーカーライフサイクルモデル適応可能: カスタムスクリプト (1) と特定のワーカーフラグが必要。適応可能: burstモード (19) が、ほぼネイティブなエフェメラルモデルを提供。ネイティブエフェメラル (タスク毎): 各タスクインスタンスが専用のPodで実行され、完了後に終了する (6)。ネイティブエフェメラル (実行毎): 各フロー実行が専用のプロセス/コンテナで実行され、完了後に終了する (8)。動的サブタスク生成優: Celery Canvas (chain, group) は強力で表現力が高い (17)。良: タスク内からq.enqueue()を標準的なPython関数呼び出しとして使用可能 (31)。優: 動的タスクマッピング (expand) はこのパターンのための専用機能 (10)。優: 完全に動的でPythonネイティブな制御フローがコア設計思想 (43)。実装の複雑性高: ユーザーは回復力のあるステートフルな管理アプリケーションを設計、構築、維持する必要がある。中〜高: burstモードによりワーカーロジックは簡素化されるが、管理部分は依然としてカスタム。中: KubernetesクラスターとPod設定 (pod_override) の知識が必要 (6)。低〜中: Python中心。主な課題は、実行毎のエフェメラルモデルに適合するようワークフローをモデリングすること。可観測性低: Flowerなどの外部ツールが必要で、履歴コンテキストは限定的。低: rqinfoなどの基本的な監視ツールはあるが、詳細な履歴分析機能は欠ける。高: 全てのDAG実行とタスクインスタンスの詳細な履歴ビューを持つ豊富なUI。高: 全てのフロー実行とタスク実行の詳細な履歴ビューを持つ豊富なUI。VII. 最終推奨事項と実装戦略主な推奨事項：Apache AirflowとKubernetesExecutor論拠: この構成は、ユーザーが要求したアーキテクチャの最も直接的かつネイティブな実装です。AirflowスケジューラーがMCPサーバーそのものであり、KubernetesExecutorが短命なシングルタスクランナーを起動するためのエンジンです。動的タスクマッピングはサブタスク生成のメカニズムを提供します。この組み合わせは、組み込みの、実戦で検証済みのコンポーネントのみで要求された問題全体を解決します。実装戦略:セットアップ: Kubernetesクラスター上にAirflowをデプロイし、airflow.cfgでKubernetesExecutorを使用するように設定します。DAG設計: 各「ジョブ」に対してプライマリとなるDAGを定義します。タスク実装: 最初のタスクで、必要となるサブタスクを決定し、そのリストまたは辞書を返します。動的生成: 後続のタスクで.expand()メソッドを使用し、サブタスクごとにエフェメラルなワーカーPodを動的に生成します（10）。監視: Airflow UIを利用して、メインのDAG実行と動的に生成された全てのタスクインスタンスの状態を監視します。副次的な推奨事項：Prefect論拠: ユーザーの環境がKubernetesネイティブでない場合、またはより柔軟でPythonネイティブな開発体験を優先する場合には、Prefectが優れた代替案となります。動的な「コードとしてのワークフロー」ロジックのサポートは、Airflowよりも優れていると言えます。実装戦略:セットアップ: Prefectサーバーをデプロイ（またはPrefect Cloudを利用）し、ワークプール（例：ProcessまたはDockerタイプ）を設定します。ワークフロー設計: ここで選択が必要です。オプションA（カスタムマネージャー）: Prefect APIをクエリして保留中のジョブを確認し（40）、prefect worker start --run-onceプロセスを起動して実行する管理スクリプトを作成します（8）。オプションB（Prefectらしいアプローチ）: 「ジョブ」をオーケストレーターフローとして設計します。このフローの最初のタスクがサブタスクを決定し、ループ内で各作業に対してmy_sub_flow.submit()を呼び出します。各.submit()呼び出しは独立したフロー実行を生成し、それは長寿命のワーカーによってピックアップされ、独自のエフェメラルなプロセス/コンテナで実行されます（8）。ワークプール/キューの同時実行数制限（42）を利用して、「1つのアクティブなランナー」という制約を近似的に実現できます。こちらがより堅牢でPrefectネイティブなアプローチです。緊急時の推奨事項：Redis Queue (RQ)論拠: ユーザーの主要な制約がシンプルさと最小限のインフラであり、かつコントロールプレーンのロジックを自ら構築・維持する意欲がある場合、RQはそのburstモードにより、タスクキューの中では最良の選択肢となります。実装戦略:セットアップ: 単一のRedisインスタンスを用意します。管理スクリプト: 以下の機能を持つPythonサービスを作成します。「保留中」状態のジョブを定期的にクエリする（この状態ロジックは、例えば別のRedisハッシュにカスタムで構築する必要があります）。「実行中ジョブ」の登録（別のカスタムRedisセット）を確認し、そのジョブに対してワーカーがアクティブでないことを確認する。保留中かつ非アクティブの場合、ジョブ固有のRedisキューに単一のタスクを追加し、「実行中」登録にジョブを追加し、subprocess.run(["rq", "worker", "--burst", "job_specific_queue"])を実行する。完了時またはタイムアウト時に「実行中」登録からジョブを削除するクリーンアップロジックを含む。タスク実装: ワーカーによって実行されるPython関数は、q.enqueue()を使用してサブタスクを作成できます。
C
C
iiA
