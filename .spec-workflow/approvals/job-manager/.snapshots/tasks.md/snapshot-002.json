{
  "id": "snapshot_1759336753721_8g5203asj",
  "approvalId": "approval_1759336601627_5i3ku0c7u",
  "approvalTitle": "Job Manager Implementation Tasks",
  "version": 2,
  "timestamp": "2025-10-01T16:39:13.721Z",
  "trigger": "approved",
  "status": "pending",
  "content": "# Tasks Document: Job Manager MVP\n\n## Task 1: Create Core Domain Models\n\n- [ ] 1. Create core domain models in src/air_executor/core/\n  - Files: `src/air_executor/core/job.py`, `src/air_executor/core/task.py`\n  - Define Job, JobState, Task, TaskStatus, TaskQueue classes with pydantic\n  - Implement state transition methods and validation logic\n  - Add serialization methods (from_file, to_file for Job)\n  - Purpose: Establish type-safe domain models for job/task management\n  - _Leverage: pydantic BaseModel, pathlib, datetime, Enum_\n  - _Requirements: 1.1, 1.2, 1.3, 5.1, 5.2_\n  - _Prompt: Implement the task for spec job-manager. First run spec-workflow-guide to get the workflow guide, then implement the task:\n\n    Role: Python Domain Modeling Specialist with expertise in pydantic and type systems\n\n    Task: Create comprehensive domain models for Job and Task entities following requirements 1.1-1.3, 5.1-5.2 from requirements.md. Implement Job class with state management (JobState enum: waiting, working, completed, failed), Task class with status tracking (TaskStatus enum: pending, running, completed, failed), and TaskQueue class for managing task collections. Include validation, state transition logic, dependency checking, and file serialization methods.\n\n    Restrictions:\n    - Must use pydantic BaseModel for all models\n    - No external dependencies beyond pydantic, datetime, pathlib, typing\n    - No orchestrator-specific logic (keep domain models pure)\n    - Validate all state transitions (e.g., can't go from completed to waiting)\n    - Validate job names (alphanumeric, dash, underscore only)\n\n    _Leverage:\n    - pydantic for validation and serialization\n    - Enum for type-safe state/status values\n    - pathlib for file operations\n    - datetime for timestamps\n\n    _Requirements Addressed:\n    - 1.1: Job directory structure with state.json, tasks.json\n    - 1.2: Atomic state updates in state.json\n    - 1.3: Task queueing with unique IDs and pending status\n    - 5.1: Task definition with command, args, dependencies\n    - 5.2: Atomic task append with incrementing IDs\n\n    Success Criteria:\n    - All classes have complete type hints and validation\n    - Job state transitions enforce valid state machine (waiting → working → completed/failed)\n    - Task status transitions are validated and timestamped\n    - TaskQueue supports dependency checking (is_ready method)\n    - Serialization methods produce valid JSON matching data models spec\n    - All validation errors produce clear, actionable messages\n\n    Instructions:\n    1. Edit tasks.md and change this task from [ ] to [-] (in progress)\n    2. Create src/air_executor/core/ directory if not exists\n    3. Create __init__.py with exports\n    4. Implement job.py with Job, JobState classes\n    5. Implement task.py with Task, TaskStatus, TaskQueue classes\n    6. Write unit tests in tests/unit/test_job.py and tests/unit/test_task.py\n    7. Run tests with pytest and ensure >90% coverage\n    8. Edit tasks.md and change this task from [-] to [x] (completed)_\n\n- [ ] 2. Create File Storage Implementation\n\n  - Files: `src/air_executor/storage/file_store.py`\n  - Implement FileStore class with atomic JSON read/write operations\n  - Add methods for job/task persistence (read_job_state, write_job_state, etc.)\n  - Implement directory creation, job listing, and error handling\n  - Purpose: Provide reliable file-based persistence with atomic writes\n  - _Leverage: pathlib, json, tempfile for atomic writes_\n  - _Requirements: 1.1, 1.2, 1.3, 1.4_\n  - _Prompt: Implement the task for spec job-manager. First run spec-workflow-guide to get the workflow guide, then implement the task:\n\n    Role: Backend Storage Engineer with expertise in file systems and atomic operations\n\n    Task: Implement FileStore class following requirements 1.1-1.4 from requirements.md. Provide atomic JSON persistence for job state and task queues. Support read/write operations for .air-executor/jobs/{name}/state.json and tasks.json files with atomic write guarantees (write to temp file, then rename). Include directory creation, job listing, and robust error handling for corrupted files.\n\n    Restrictions:\n    - All writes must be atomic (write temp file, then os.rename)\n    - Must handle partial writes and corrupted JSON gracefully\n    - No database dependencies (pure file-based storage)\n    - File permissions must be 0700 for job directories\n    - Path traversal prevention (validate job names)\n\n    _Leverage:\n    - pathlib.Path for filesystem operations\n    - json for serialization\n    - tempfile.NamedTemporaryFile for atomic writes\n    - os.rename() for atomic file replacement\n\n    _Requirements Addressed:\n    - 1.1: Create job directory with state.json, tasks.json, logs/\n    - 1.2: Atomically update state.json on state changes\n    - 1.3: Append tasks to tasks.json atomically\n    - 1.4: Restore all job states from filesystem on restart\n\n    Success Criteria:\n    - All write operations are atomic (no partial writes possible)\n    - Corrupted JSON files detected and logged without crashing\n    - Directory creation is idempotent and creates full structure\n    - Job listing handles missing/invalid directories gracefully\n    - Unit tests verify atomic writes under concurrent access (mock scenarios)\n    - File permissions enforced (0700 for job directories)\n\n    Instructions:\n    1. Edit tasks.md and change this task from [ ] to [-]\n    2. Create src/air_executor/storage/ directory\n    3. Create __init__.py with exports\n    4. Implement file_store.py with FileStore class\n    5. Write unit tests in tests/unit/test_file_store.py\n    6. Test atomic writes, error handling, directory creation\n    7. Run tests with pytest and ensure >85% coverage\n    8. Edit tasks.md and change this task from [-] to [x]_\n\n- [ ] 3. Create Runner Interface and Subprocess Implementation\n\n  - Files: `src/air_executor/core/runner.py`, `src/air_executor/runners/subprocess_runner.py`\n  - Define Runner protocol with spawn, is_alive, terminate methods\n  - Implement SubprocessRunner with process lifecycle management\n  - Add timeout handling (SIGTERM → SIGKILL escalation)\n  - Purpose: Provide abstraction for task execution with concrete subprocess implementation\n  - _Leverage: typing.Protocol, subprocess, psutil, signal_\n  - _Requirements: 4.1, 4.2, 4.3, 4.4, 4.5_\n  - _Prompt: Implement the task for spec job-manager. First run spec-workflow-guide to get the workflow guide, then implement the task:\n\n    Role: Systems Programmer with expertise in process management and Unix signals\n\n    Task: Implement Runner protocol and SubprocessRunner class following requirements 4.1-4.5 from requirements.md. Define abstract Runner protocol for task execution abstraction. Implement concrete SubprocessRunner that spawns subprocess with command `air-executor run-task --job {job} --task {task}`, tracks PID, checks process liveness, and handles graceful/forceful termination with timeout escalation (SIGTERM → wait → SIGKILL).\n\n    Restrictions:\n    - Runner protocol must be implementation-agnostic (no subprocess details)\n    - SubprocessRunner must handle zombie processes (wait/reap)\n    - Must verify PID belongs to our spawned process (avoid killing wrong process)\n    - Timeout enforcement required (SIGTERM after timeout, SIGKILL after grace period)\n    - No shell=True in subprocess (security: prevent command injection)\n\n    _Leverage:\n    - typing.Protocol for interface definition\n    - subprocess.Popen for process spawning\n    - psutil for process existence and management\n    - signal for SIGTERM/SIGKILL\n    - time.sleep for timeout waiting\n\n    _Requirements Addressed:\n    - 4.1: Execute subprocess with air-executor run-task command\n    - 4.2: Update job state to \"working\" on spawn\n    - 4.3: Mark task completed on exit code 0\n    - 4.4: Mark task failed on exit code >0\n    - 4.5: Enforce timeout with SIGTERM → SIGKILL escalation\n\n    Success Criteria:\n    - Runner protocol defined with spawn, is_alive, terminate methods\n    - SubprocessRunner spawns process and returns valid PID\n    - is_alive correctly detects running vs exited processes\n    - terminate sends SIGTERM, waits 10s, then SIGKILL if needed\n    - Unit tests verify timeout handling with mock subprocess\n    - Integration tests verify real subprocess lifecycle\n\n    Instructions:\n    1. Edit tasks.md and change this task from [ ] to [-]\n    2. Create src/air_executor/core/runner.py with Runner protocol\n    3. Create src/air_executor/runners/ directory\n    4. Implement subprocess_runner.py with SubprocessRunner class\n    5. Write unit tests in tests/unit/test_subprocess_runner.py\n    6. Write integration tests in tests/integration/test_runner_lifecycle.py\n    7. Run tests with pytest and ensure >80% coverage\n    8. Edit tasks.md and change this task from [-] to [x]_\n\n- [ ] 4. Create Configuration Management\n\n  - Files: `src/air_executor/manager/config.py`\n  - Define Config class with pydantic validation\n  - Implement from_file classmethod for YAML loading\n  - Add default values and validation rules\n  - Purpose: Provide validated, type-safe configuration management\n  - _Leverage: pydantic BaseModel, pyyaml, pathlib_\n  - _Requirements: 8.1, 8.2, 8.3, 8.4, 8.5_\n  - _Prompt: Implement the task for spec job-manager. First run spec-workflow-guide to get the workflow guide, then implement the task:\n\n    Role: Configuration Management Specialist with expertise in validation and YAML parsing\n\n    Task: Implement Config class following requirements 8.1-8.5 from requirements.md. Create pydantic model with fields: poll_interval (1-60s, default 5), task_timeout (60-7200s, default 1800), max_concurrent_runners (1-50, default 10), base_path (default .air-executor), log_level (default INFO), log_format (default json). Support loading from .air-executor/config.yaml with validation, defaults for missing values, and clear error messages for invalid config.\n\n    Restrictions:\n    - Must validate all numeric ranges (use pydantic Field with ge/le)\n    - Must provide actionable error messages with line numbers for YAML errors\n    - Must handle missing file gracefully (return defaults)\n    - Must log warnings for unknown keys but not fail\n    - No hot reload (restart required for config changes)\n\n    _Leverage:\n    - pydantic BaseModel with Field validators\n    - pyyaml for YAML parsing (safe_load)\n    - pathlib for file handling\n    - pydantic ValidationError for detailed error messages\n\n    _Requirements Addressed:\n    - 8.1: Read from .air-executor/config.yaml, use defaults if missing\n    - 8.2: Validate config and exit with error messages if invalid\n    - 8.3: Restart required for config changes (no hot reload)\n    - 8.4: Use documented defaults for missing optional values\n    - 8.5: Log warnings for unknown keys, continue with valid ones\n\n    Success Criteria:\n    - Config loads from YAML file with all fields validated\n    - Invalid values produce clear error messages (e.g., \"poll_interval must be 1-60\")\n    - Missing file returns default Config without error\n    - Unknown keys logged as warnings but don't prevent loading\n    - Unit tests verify all validation rules and error messages\n\n    Instructions:\n    1. Edit tasks.md and change this task from [ ] to [-]\n    2. Create src/air_executor/manager/ directory\n    3. Create __init__.py with exports\n    4. Implement config.py with Config class\n    5. Write unit tests in tests/unit/test_config.py\n    6. Test validation, defaults, error messages, unknown keys\n    7. Run tests with pytest and ensure >90% coverage\n    8. Edit tasks.md and change this task from [-] to [x]_\n\n- [ ] 5. Create Runner Spawner Component\n\n  - Files: `src/air_executor/manager/spawner.py`\n  - Implement RunnerSpawner class with PID tracking\n  - Add spawn_if_needed method with parallel spawning (up to max_concurrent_runners)\n  - Implement stale PID cleanup and active runner checking\n  - Purpose: Manage runner lifecycle with concurrency control and PID tracking\n  - _Leverage: Runner protocol, FileStore, concurrent.futures_\n  - _Requirements: 3.1, 3.2, 3.3, 3.4, 3.5, 4.1, 4.2_\n  - _Prompt: Implement the task for spec job-manager. First run spec-workflow-guide to get the workflow guide, then implement the task:\n\n    Role: Concurrency Engineer with expertise in process orchestration and resource management\n\n    Task: Implement RunnerSpawner class following requirements 3.1-3.5, 4.1-4.2 from requirements.md. Provide runner lifecycle management with PID tracking via .air-executor/jobs/{name}/runner.pid files. Implement spawn_if_needed method that spawns runners for multiple jobs in parallel (up to max_concurrent_runners limit). Enforce single-runner-per-job constraint by checking PID file existence and process liveness. Clean up stale PID files for dead processes.\n\n    Restrictions:\n    - Must enforce single runner per job (check PID file + process liveness)\n    - Must clean up stale PIDs before allowing new spawn\n    - Parallel spawning must respect max_concurrent_runners limit\n    - PID file must be created BEFORE runner starts (prevent race condition)\n    - Must handle runner spawn failures gracefully (log, clean up PID, continue)\n\n    _Leverage:\n    - Runner protocol for process operations\n    - FileStore for PID file read/write\n    - concurrent.futures.ThreadPoolExecutor for parallel spawning\n    - psutil for process existence checking\n\n    _Requirements Addressed:\n    - 3.1: Check PID file existence before spawning\n    - 3.2: Create PID file with process ID and timestamp before execution\n    - 3.3: Remove PID file when runner terminates\n    - 3.4: Clean up stale PID if process is dead\n    - 3.5: Spawn runners in parallel (one per job, max 10 concurrent)\n    - 4.1: Execute subprocess with air-executor run-task command\n    - 4.2: Set job state to \"working\" when runner spawns\n\n    Success Criteria:\n    - spawn_if_needed correctly identifies jobs needing runners\n    - PID files created atomically before runner starts\n    - Stale PID cleanup handles crashed runners gracefully\n    - Parallel spawning respects max_concurrent_runners limit\n    - Runner spawn failures isolated (don't affect other jobs)\n    - Unit tests with mocked Runner and FileStore verify logic\n    - Integration tests verify real PID tracking and cleanup\n\n    Instructions:\n    1. Edit tasks.md and change this task from [ ] to [-]\n    2. Create spawner.py in src/air_executor/manager/\n    3. Implement RunnerSpawner class with all methods\n    4. Write unit tests in tests/unit/test_spawner.py\n    5. Write integration tests in tests/integration/test_spawner_lifecycle.py\n    6. Run tests with pytest and ensure >80% coverage\n    7. Edit tasks.md and change this task from [-] to [x]_\n\n- [ ] 6. Create Job Poller Component\n\n  - Files: `src/air_executor/manager/poller.py`\n  - Implement JobPoller class with polling loop\n  - Add signal handling for graceful shutdown (SIGTERM)\n  - Implement per-job error isolation and state management\n  - Purpose: Provide main orchestration loop that discovers jobs and triggers spawning\n  - _Leverage: FileStore, RunnerSpawner, signal, time, TaskQueue_\n  - _Requirements: 2.1, 2.2, 2.3, 2.4, 2.5, 6.1, 6.2, 6.3_\n  - _Prompt: Implement the task for spec job-manager. First run spec-workflow-guide to get the workflow guide, then implement the task:\n\n    Role: Event Loop Architect with expertise in polling systems and signal handling\n\n    Task: Implement JobPoller class following requirements 2.1-2.5, 6.1-6.3 from requirements.md. Create polling loop that runs every poll_interval seconds, scans .air-executor/jobs/ directory, loads job states, checks for pending tasks and active runners, and invokes RunnerSpawner for jobs that need work. Handle SIGTERM for graceful shutdown (complete current cycle, then exit within 10s). Isolate errors per job (log error, continue with other jobs).\n\n    Restrictions:\n    - Polling loop must not block longer than poll_interval\n    - Must complete current poll cycle before shutdown (no interruption mid-cycle)\n    - Job errors must not crash poller (isolation via try/except)\n    - Must query all jobs within 100ms per job (performance requirement)\n    - Must detect job completion (no pending tasks, no active runner → completed state)\n\n    _Leverage:\n    - FileStore for job discovery and state loading\n    - RunnerSpawner for runner lifecycle\n    - signal.signal for SIGTERM handling\n    - time.sleep for poll interval\n    - TaskQueue for pending task detection\n    - structlog for structured logging\n\n    _Requirements Addressed:\n    - 2.1: Start polling loop with configurable interval (default 5s)\n    - 2.2: Check status of all jobs within 100ms per job\n    - 2.3: Add jobs with pending tasks and no active runner to spawn queue\n    - 2.4: Log error for failed job, continue with remaining jobs\n    - 2.5: Handle SIGTERM, complete current cycle, shutdown within 10s\n    - 6.1: Detect no pending tasks and no active runner → set completed\n    - 6.2: Detect failed task → set job to failed, stop spawning\n    - 6.3: Log completion time and task statistics\n\n    Success Criteria:\n    - Polling loop runs continuously with correct interval\n    - SIGTERM triggers graceful shutdown (completes cycle, exits <10s)\n    - Job errors isolated and logged without crashing poller\n    - Job completion detected and state updated correctly\n    - Jobs with pending tasks and no runner added to spawn queue\n    - Unit tests with mocked dependencies verify logic\n    - Integration tests verify full poll cycle with real files\n\n    Instructions:\n    1. Edit tasks.md and change this task from [ ] to [-]\n    2. Create poller.py in src/air_executor/manager/\n    3. Implement JobPoller class with start, poll_once, stop methods\n    4. Write unit tests in tests/unit/test_poller.py\n    5. Write integration tests in tests/integration/test_poller_lifecycle.py\n    6. Run tests with pytest and ensure >85% coverage\n    7. Edit tasks.md and change this task from [-] to [x]_\n\n- [ ] 7. Create CLI Commands\n\n  - Files: `src/air_executor/cli/main.py`, `src/air_executor/cli/commands.py`\n  - Implement CLI using click framework\n  - Add commands: start, stop, status, logs, reset\n  - Use rich library for formatted table output\n  - Purpose: Provide user-friendly command-line interface for job manager control\n  - _Leverage: click, rich, FileStore, Job, Config_\n  - _Requirements: 7.1, 7.2, 7.3, 7.4, 7.5_\n  - _Prompt: Implement the task for spec job-manager. First run spec-workflow-guide to get the workflow guide, then implement the task:\n\n    Role: CLI Developer with expertise in click framework and terminal UI design\n\n    Task: Implement CLI commands following requirements 7.1-7.5 from requirements.md. Create main.py as entry point with click group. Implement commands: start (spawn job manager daemon, output PID), stop (send SIGTERM to manager, wait for shutdown), status (display table of jobs with state/tasks/runner), logs (display task logs from jobs/{name}/logs/), reset (reset job to waiting state with confirmation). Use rich library for formatted, color-coded output.\n\n    Restrictions:\n    - start command must daemonize process (background execution)\n    - stop command must handle missing PID gracefully\n    - status command must work even if manager is stopped\n    - logs command must support --tail option (default 50 lines)\n    - reset command must require confirmation prompt\n\n    _Leverage:\n    - click for command parsing and options\n    - rich.console and rich.table for formatted output\n    - rich.syntax for log syntax highlighting\n    - FileStore for job data access\n    - subprocess for daemon spawning\n    - os.kill for sending signals\n\n    _Requirements Addressed:\n    - 7.1: air-executor start → start manager daemon, output PID\n    - 7.2: air-executor stop → send SIGTERM, wait for shutdown\n    - 7.3: air-executor status → display job table (state, pending tasks, runner status)\n    - 7.4: air-executor logs --job X → output task logs from jobs/X/logs/\n    - 7.5: air-executor reset --job X → reset to waiting with confirmation\n\n    Success Criteria:\n    - All commands execute with correct exit codes (0 success, 1 error)\n    - start command spawns background process and outputs PID\n    - stop command gracefully terminates manager\n    - status command displays formatted table with color-coded states\n    - logs command displays task logs with syntax highlighting\n    - reset command requires confirmation and updates job state\n    - Unit tests verify command logic with mocked dependencies\n    - E2E tests verify full CLI workflow\n\n    Instructions:\n    1. Edit tasks.md and change this task from [ ] to [-]\n    2. Create src/air_executor/cli/ directory\n    3. Create __init__.py with exports\n    4. Implement main.py with click group and command entry point\n    5. Implement commands.py with all command implementations\n    6. Write unit tests in tests/unit/test_cli.py\n    7. Write E2E tests in tests/e2e/test_cli_workflow.py\n    8. Run tests with pytest and ensure >75% coverage\n    9. Edit tasks.md and change this task from [-] to [x]_\n\n- [ ] 8. Create Package Structure and Entry Points\n\n  - Files: `setup.py`, `pyproject.toml`, `requirements.txt`, `Makefile`\n  - Set up Python package with entry points for CLI\n  - Define dependencies (pydantic, click, rich, pyyaml, psutil, structlog)\n  - Create Makefile for common tasks (install, test, run)\n  - Purpose: Enable package installation and distribution\n  - _Leverage: setuptools, pip-tools_\n  - _Requirements: All (packaging and distribution)_\n  - _Prompt: Implement the task for spec job-manager. First run spec-workflow-guide to get the workflow guide, then implement the task:\n\n    Role: Python Packaging Engineer with expertise in setuptools and dependency management\n\n    Task: Create Python package structure for air-executor. Implement setup.py with package metadata, dependencies, and console_scripts entry point for air-executor CLI. Create pyproject.toml with project configuration (black, isort, mypy settings). Generate requirements.txt with pinned dependencies. Create Makefile with targets: install, test, lint, format, run. Ensure package is pip-installable.\n\n    Restrictions:\n    - Must use src/ layout (importable as air_executor package)\n    - Entry point must be air-executor = air_executor.cli.main:cli\n    - requirements.txt must pin exact versions for reproducibility\n    - Makefile must work on Linux/macOS (use POSIX commands)\n    - Must include dev dependencies (pytest, black, mypy, ruff)\n\n    _Leverage:\n    - setuptools for package definition\n    - pip-tools for requirements management\n    - make for task automation\n    - pyproject.toml for tool configuration\n\n    _Requirements Addressed:\n    - All requirements (enables entire system to be installed and run)\n    - Dependency management for all required libraries\n    - CLI entry point for user-friendly execution\n\n    Success Criteria:\n    - Package is pip-installable with pip install -e .\n    - air-executor command is available after installation\n    - make install sets up virtual environment and installs package\n    - make test runs pytest with coverage\n    - make lint runs ruff and mypy\n    - make format runs black and isort\n    - All dependencies are pinned in requirements.txt\n\n    Instructions:\n    1. Edit tasks.md and change this task from [ ] to [-]\n    2. Create setup.py with package metadata and dependencies\n    3. Create pyproject.toml with tool configurations\n    4. Create requirements.txt with pinned dependencies\n    5. Create requirements-dev.txt with dev dependencies\n    6. Create Makefile with all targets\n    7. Test installation with pip install -e .\n    8. Verify air-executor command works\n    9. Edit tasks.md and change this task from [-] to [x]_\n\n- [ ] 9. Write Integration Tests\n\n  - Files: `tests/integration/test_manager_e2e.py`, `tests/integration/test_state_persistence.py`\n  - Write end-to-end test for full manager lifecycle\n  - Test state persistence and recovery after restart\n  - Test multi-job concurrent execution\n  - Purpose: Verify system works correctly as integrated whole\n  - _Leverage: pytest, tmpdir fixture, real subprocess execution_\n  - _Requirements: All (integration validation)_\n  - _Prompt: Implement the task for spec job-manager. First run spec-workflow-guide to get the workflow guide, then implement the task:\n\n    Role: QA Engineer with expertise in integration testing and system verification\n\n    Task: Write comprehensive integration tests covering full job manager lifecycle. Test scenarios: 1) Full cycle (start manager → spawn runner → execute task → complete job → stop manager), 2) State persistence (create job → stop manager → restart → verify state restored), 3) Multi-job execution (multiple jobs with tasks → verify parallel runner spawning), 4) Error recovery (corrupted state file → verify graceful handling). Use real filesystem (tmpdir) and real subprocess execution.\n\n    Restrictions:\n    - Must use temporary directories (pytest tmpdir fixture)\n    - Must verify file contents directly (state.json, tasks.json, PID files)\n    - Must verify process lifecycle (PID exists, process terminates)\n    - Must test both success and failure scenarios\n    - Tests must be isolated (no shared state between tests)\n\n    _Leverage:\n    - pytest fixtures for setup/teardown\n    - tmpdir fixture for temporary filesystem\n    - subprocess for process execution\n    - psutil for process verification\n    - time.sleep for polling simulation\n\n    _Requirements Addressed:\n    - All requirements (integration testing validates entire system)\n    - Verify state persistence across restarts\n    - Verify concurrent runner spawning\n    - Verify error handling and recovery\n\n    Success Criteria:\n    - E2E test verifies full manager lifecycle from start to completion\n    - State persistence test verifies restart recovery\n    - Multi-job test verifies parallel spawning (up to max_concurrent_runners)\n    - Error recovery test verifies graceful handling of corrupted files\n    - All tests pass consistently (no flaky tests)\n    - Test coverage includes all critical paths\n\n    Instructions:\n    1. Edit tasks.md and change this task from [ ] to [-]\n    2. Create tests/integration/ directory\n    3. Create __init__.py\n    4. Implement test_manager_e2e.py with full lifecycle test\n    5. Implement test_state_persistence.py with restart recovery test\n    6. Implement test_multi_job.py with concurrent execution test\n    7. Run tests with pytest -v tests/integration/\n    8. Verify all tests pass\n    9. Edit tasks.md and change this task from [-] to [x]_\n\n- [ ] 10. Write Documentation and Examples\n\n  - Files: `README.md`, `docs/quickstart.md`, `examples/simple_job.json`\n  - Write README with project overview, installation, and quick start\n  - Create quickstart guide with step-by-step tutorial\n  - Add example job definitions for common use cases\n  - Purpose: Enable users to understand and use the system\n  - _Leverage: markdown, example configs_\n  - _Requirements: All (documentation)_\n  - _Prompt: Implement the task for spec job-manager. First run spec-workflow-guide to get the workflow guide, then implement the task:\n\n    Role: Technical Writer with expertise in developer documentation and tutorials\n\n    Task: Create comprehensive user documentation. Write README.md with project overview, features, installation instructions (pip install), quick start example, and links to detailed docs. Create docs/quickstart.md with step-by-step tutorial: 1) Install, 2) Create job definition, 3) Start manager, 4) Check status, 5) View logs, 6) Stop manager. Add examples/simple_job.json with annotated job definition. Ensure documentation matches actual implementation and CLI commands.\n\n    Restrictions:\n    - README must be concise (<500 lines), not exhaustive\n    - Quick start must be copy-paste executable\n    - Examples must be valid and tested\n    - Documentation must match actual CLI command syntax\n    - Must include troubleshooting section for common issues\n\n    _Leverage:\n    - Markdown for formatting\n    - Code blocks with syntax highlighting\n    - Mermaid diagrams for architecture visualization\n    - Example job definitions in JSON\n\n    _Requirements Addressed:\n    - All requirements (documentation enables usage)\n    - User understanding of system architecture\n    - Clear instructions for common operations\n\n    Success Criteria:\n    - README includes project overview, features, installation, quick start\n    - Quick start guide is executable and produces expected results\n    - Example job definitions are valid and well-commented\n    - Troubleshooting section covers common issues (stale PIDs, config errors)\n    - Documentation is clear and actionable for new users\n    - All CLI commands are accurately documented\n\n    Instructions:\n    1. Edit tasks.md and change this task from [ ] to [-]\n    2. Create README.md in project root\n    3. Create docs/quickstart.md\n    4. Create examples/simple_job.json with comments\n    5. Create examples/dynamic_tasks.json showing sub-task queueing\n    6. Review documentation for accuracy against implementation\n    7. Test quick start guide by following steps\n    8. Edit tasks.md and change this task from [-] to [x]_\n",
  "fileStats": {
    "size": 29260,
    "lines": 543,
    "lastModified": "2025-10-01T16:36:21.363Z"
  },
  "comments": []
}
